:PROPERTIES:
:ID:       9E6705A2-4588-4119-BA73-E7DE199D119D
:END:
#+title: Adam

Adam stands for adaptive moments.
Comparing to [[id:09EF457A-2143-4927-8C94-F21164C1E876][RMSProp]], Adam adds [[id:D44B9227-4AF2-42FD-837F-ECE816A3ECAB][Momentum]] to gradient.

\begin{equation}
\boldsymbol{r} \leftarrow \rho \boldsymbol{r}+(1-\rho) \boldsymbol{g} \odot \boldsymbol{g}
\end{equation}

\begin{equation}
\boldsymbol{\theta} \leftarrow \boldsymbol{\theta} - \frac{\epsilon}{\sqrt{\delta+\boldsymbol{r}}} \odot \boldsymbol{g}
\end{equation}


Where $\epsilon$ is the learning rate, $\rho$ is the decay rate, $\delta$ is a small constant, $\boldsymbol{r}$ is initialized to $0$.
